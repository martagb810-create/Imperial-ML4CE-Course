{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6216191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import MLCE_CWBO2025.virtual_lab as virtual_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e680e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Objective wrapper ----------------\n",
    "def objective_func(X):\n",
    "    return np.array(virtual_lab.conduct_experiment(X), dtype=float)\n",
    "\n",
    "\n",
    "# ---------------- Constants / bounds ----------------\n",
    "CELLTYPES = [\"celltype_1\", \"celltype_2\", \"celltype_3\"]\n",
    "\n",
    "BOUNDS_5 = np.array(\n",
    "    [\n",
    "        [30.0, 40.0],  # T\n",
    "        [6.0, 8.0],    # pH\n",
    "        [0.0, 50.0],   # F1\n",
    "        [0.0, 50.0],   # F2\n",
    "        [0.0, 50.0],   # F3\n",
    "    ],\n",
    "    dtype=float,\n",
    ")\n",
    "\n",
    "\n",
    "def norm5(X):\n",
    "    return (X - BOUNDS_5[:, 0]) / (BOUNDS_5[:, 1] - BOUNDS_5[:, 0])\n",
    "\n",
    "\n",
    "def denorm5(Xn):\n",
    "    return Xn * (BOUNDS_5[:, 1] - BOUNDS_5[:, 0]) + BOUNDS_5[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d28bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- GP helpers ----------------\n",
    "def rbf_kernel(X1, X2, lengthscales, signal_var):\n",
    "    scaled = (X1[:, None, :] - X2[None, :, :]) / lengthscales\n",
    "    sqdist = np.sum(scaled * scaled, axis=2)\n",
    "    return signal_var * np.exp(-0.5 * sqdist)\n",
    "\n",
    "\n",
    "def gp_posterior_std(X_train, y_train, X_test, lengthscales, signal_var, noise_var):\n",
    "    \"\"\"\n",
    "    GP posterior on standardised y.\n",
    "    Returns: mean_s, var_s, y_mean, y_std\n",
    "    where y_s = (y - y_mean)/y_std\n",
    "    \"\"\"\n",
    "    y_train = np.asarray(y_train, dtype=float).reshape(-1)\n",
    "    y_mean = float(np.mean(y_train))\n",
    "    y_std = float(np.std(y_train))\n",
    "    if y_std < 1e-8:\n",
    "        y_std = 1.0\n",
    "    y_s = (y_train - y_mean) / y_std\n",
    "\n",
    "    K = rbf_kernel(X_train, X_train, lengthscales, signal_var)\n",
    "    n = X_train.shape[0]\n",
    "    K[np.diag_indices(n)] += noise_var\n",
    "\n",
    "    # Cholesky + jitter\n",
    "    try:\n",
    "        L = np.linalg.cholesky(K)\n",
    "    except np.linalg.LinAlgError:\n",
    "        K[np.diag_indices(n)] += 1e-8\n",
    "        L = np.linalg.cholesky(K)\n",
    "\n",
    "    alpha = np.linalg.solve(L.T, np.linalg.solve(L, y_s))\n",
    "    K_s = rbf_kernel(X_train, X_test, lengthscales, signal_var)\n",
    "\n",
    "    mean_s = K_s.T @ alpha\n",
    "\n",
    "    v = np.linalg.solve(L, K_s)\n",
    "    K_ss_diag = np.full(X_test.shape[0], signal_var, dtype=float)  # RBF: k(x,x)=signal_var\n",
    "    var_s = K_ss_diag - np.sum(v * v, axis=0)\n",
    "    var_s = np.maximum(var_s, 1e-12)\n",
    "\n",
    "    return mean_s, var_s, y_mean, y_std\n",
    "\n",
    "\n",
    "def expected_improvement_std(mean_s, var_s, best_s, xi):\n",
    "    std_s = np.sqrt(var_s)\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        z = (mean_s - best_s - xi) / std_s\n",
    "        Phi = scipy.stats.norm.cdf(z)\n",
    "        phi = scipy.stats.norm.pdf(z)\n",
    "        ei = (mean_s - best_s - xi) * Phi + std_s * phi\n",
    "        ei[std_s < 1e-12] = 0.0\n",
    "    return ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1464f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- V2.1 BO ----------------\n",
    "class BO:\n",
    "    \"\"\"\n",
    "    V2.1:\n",
    "    - Separate GP per celltype (5D continuous only)\n",
    "    - Standardise y per celltype GP\n",
    "    - Greedy batch: choose highest EI across celltypes each pick\n",
    "    - Kriging Believer fantasy update within the selected celltype\n",
    "    - Scoring-aware schedule: exploration early, exploitation later\n",
    "    - Proper time bookkeeping: dt_ms per objective call + zero padding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_initial, iterations, batch, objective_func):\n",
    "        self.iterations = int(iterations)\n",
    "        self.batch = int(batch)\n",
    "\n",
    "        # Hyperparams in normalised [0,1] space\n",
    "        self.lengthscales = np.array([0.22, 0.22, 0.22, 0.22, 0.22], dtype=float)\n",
    "        self.signal_var = 1.0\n",
    "        self.noise_var = 1e-6\n",
    "\n",
    "        self.X = [row[:] for row in X_initial]\n",
    "        self.Y = np.array([], dtype=float)\n",
    "        self.time = []  # ms, one entry per evaluation\n",
    "\n",
    "        # --- Evaluate initial points (1 objective call) ---\n",
    "        t0 = datetime.timestamp(datetime.now())\n",
    "        Y_init = objective_func(self.X)\n",
    "        dt_ms = 1000.0 * (datetime.timestamp(datetime.now()) - t0)\n",
    "\n",
    "        self.Y = np.concatenate([self.Y, Y_init])\n",
    "        self.time += [dt_ms] + [0.0] * (len(Y_init) - 1)\n",
    "\n",
    "        self.best_so_far = float(np.max(self.Y)) if len(self.Y) else -np.inf\n",
    "\n",
    "        # --- Optimisation rounds: each round is 1 objective call returning <=batch points ---\n",
    "        for r in range(self.iterations):\n",
    "            X_batch = self._propose_batch(round_index=r)\n",
    "            t0 = datetime.timestamp(datetime.now())\n",
    "            Y_batch = objective_func(X_batch)\n",
    "            dt_ms = 1000.0 * (datetime.timestamp(datetime.now()) - t0)\n",
    "\n",
    "            self.X.extend(X_batch)\n",
    "            self.Y = np.concatenate([self.Y, Y_batch])\n",
    "            self.time += [dt_ms] + [0.0] * (len(Y_batch) - 1)\n",
    "\n",
    "            yb = float(np.max(Y_batch)) if len(Y_batch) else -np.inf\n",
    "            if yb > self.best_so_far:\n",
    "                self.best_so_far = yb\n",
    "\n",
    "    def _split_by_celltype(self):\n",
    "        data = {c: {\"Xn\": [], \"y\": []} for c in CELLTYPES}\n",
    "        for x, y in zip(self.X, self.Y):\n",
    "            c = x[5]\n",
    "            x5 = np.array([x[0], x[1], x[2], x[3], x[4]], dtype=float)\n",
    "            data[c][\"Xn\"].append(norm5(x5))\n",
    "            data[c][\"y\"].append(float(y))\n",
    "        for c in CELLTYPES:\n",
    "            data[c][\"Xn\"] = np.array(data[c][\"Xn\"], dtype=float).reshape(-1, 5)\n",
    "            data[c][\"y\"] = np.array(data[c][\"y\"], dtype=float).reshape(-1)\n",
    "        return data\n",
    "\n",
    "    def _schedule(self, round_index):\n",
    "        \"\"\"\n",
    "        Scoring-aware schedule:\n",
    "        - rounds 0-2: explore more (higher xi, more global)\n",
    "        - rounds 3-14: exploit more (lower xi, more local focus)\n",
    "        \"\"\"\n",
    "        if round_index <= 2:\n",
    "            return {\n",
    "                \"xi\": 0.05,\n",
    "                \"n_global\": 8000,\n",
    "                \"n_local\": 2000,\n",
    "                \"local_sigma\": 0.08,\n",
    "                \"force_explore_every\": 2,  # force 1 random global candidate every 2 picks\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"xi\": 0.01,\n",
    "                \"n_global\": 6000,\n",
    "                \"n_local\": 5000,\n",
    "                \"local_sigma\": 0.05,\n",
    "                \"force_explore_every\": 4,  # still keep some exploration\n",
    "            }\n",
    "\n",
    "    def _propose_batch(self, round_index):\n",
    "        data = self._split_by_celltype()\n",
    "\n",
    "        # Fantasy copies for batch construction\n",
    "        Xn_f = {c: data[c][\"Xn\"].copy() for c in CELLTYPES}\n",
    "        y_f = {c: data[c][\"y\"].copy() for c in CELLTYPES}\n",
    "\n",
    "        cfg = self._schedule(round_index)\n",
    "        xi = cfg[\"xi\"]\n",
    "        n_global = cfg[\"n_global\"]\n",
    "        n_local = cfg[\"n_local\"]\n",
    "        local_sigma = cfg[\"local_sigma\"]\n",
    "        force_explore_every = cfg[\"force_explore_every\"]\n",
    "\n",
    "        chosen = []\n",
    "\n",
    "        for k in range(self.batch):\n",
    "            # Force an occasional pure exploration point (cheap anti-stuck)\n",
    "            if force_explore_every > 0 and (k % force_explore_every == 0):\n",
    "                c = CELLTYPES[k % 3]\n",
    "                xn = np.random.rand(5)\n",
    "                x5 = denorm5(xn)\n",
    "                chosen.append([float(x5[0]), float(x5[1]), float(x5[2]), float(x5[3]), float(x5[4]), c])\n",
    "                # Fantasy: if we have a model, fantasise mean; else append 0 in y-scale\n",
    "                if y_f[c].shape[0] >= 2:\n",
    "                    mu_s, _, y_mean, y_std = gp_posterior_std(\n",
    "                        Xn_f[c], y_f[c], xn.reshape(1, 5),\n",
    "                        self.lengthscales, self.signal_var, self.noise_var\n",
    "                    )\n",
    "                    y_fant = float(mu_s[0]) * float(y_std) + float(y_mean)\n",
    "                else:\n",
    "                    y_fant = float(np.mean(y_f[c])) if y_f[c].shape[0] else 0.0\n",
    "                Xn_f[c] = np.vstack([Xn_f[c], xn.reshape(1, 5)])\n",
    "                y_f[c] = np.concatenate([y_f[c], [y_fant]])\n",
    "                continue\n",
    "\n",
    "            best_ei = -1.0\n",
    "            best_cell = None\n",
    "            best_xn = None\n",
    "            best_mu_s = None\n",
    "            best_y_mean = None\n",
    "            best_y_std = None\n",
    "\n",
    "            for c in CELLTYPES:\n",
    "                # If too little data in this celltype, treat as exploration\n",
    "                if y_f[c].shape[0] < 2:\n",
    "                    cand = np.random.rand(n_global, 5)\n",
    "                    j = random.randrange(cand.shape[0])\n",
    "                    # Give exploration a baseline EI so it competes early\n",
    "                    score = 1e-3\n",
    "                    if score > best_ei:\n",
    "                        best_ei = score\n",
    "                        best_cell = c\n",
    "                        best_xn = cand[j]\n",
    "                        best_mu_s = 0.0\n",
    "                        best_y_mean = 0.0\n",
    "                        best_y_std = 1.0\n",
    "                    continue\n",
    "\n",
    "                Xtr = Xn_f[c]\n",
    "                ytr = y_f[c]\n",
    "\n",
    "                best_idx_c = int(np.argmax(ytr))\n",
    "                centre = Xtr[best_idx_c]\n",
    "\n",
    "                global_cand = np.random.rand(n_global, 5)\n",
    "                local_cand = centre + local_sigma * np.random.randn(n_local, 5)\n",
    "                local_cand = np.clip(local_cand, 0.0, 1.0)\n",
    "                cand = np.vstack([global_cand, local_cand])\n",
    "\n",
    "                mu_s, var_s, y_mean, y_std = gp_posterior_std(\n",
    "                    Xtr, ytr, cand,\n",
    "                    self.lengthscales, self.signal_var, self.noise_var\n",
    "                )\n",
    "\n",
    "                best_s = (self.best_so_far - y_mean) / y_std\n",
    "                ei = expected_improvement_std(mu_s, var_s, best_s, xi=xi)\n",
    "                j = int(np.argmax(ei))\n",
    "\n",
    "                if float(ei[j]) > best_ei:\n",
    "                    best_ei = float(ei[j])\n",
    "                    best_cell = c\n",
    "                    best_xn = cand[j]\n",
    "                    best_mu_s = float(mu_s[j])\n",
    "                    best_y_mean = float(y_mean)\n",
    "                    best_y_std = float(y_std)\n",
    "\n",
    "            x5 = denorm5(best_xn)\n",
    "            chosen.append([float(x5[0]), float(x5[1]), float(x5[2]), float(x5[3]), float(x5[4]), best_cell])\n",
    "\n",
    "            # Kriging Believer fantasy update\n",
    "            y_fant = float(best_mu_s) * float(best_y_std) + float(best_y_mean)\n",
    "            Xn_f[best_cell] = np.vstack([Xn_f[best_cell], best_xn.reshape(1, 5)])\n",
    "            y_f[best_cell] = np.concatenate([y_f[best_cell], [y_fant]])\n",
    "\n",
    "        return chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b589658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Visualisation ----------------\n",
    "def plot_results(bo, submission=\"group1_local_v2_1.py\", out_png=\"group1_v2_1_individual.png\"):\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except Exception:\n",
    "        print(\"matplotlib not available; skipping plots.\")\n",
    "        return\n",
    "\n",
    "    Y = np.asarray(bo.Y).reshape(-1)\n",
    "    t_ms = np.asarray(bo.time).reshape(-1)\n",
    "    cum_t = np.cumsum(t_ms)\n",
    "    cum_Y = np.cumsum(Y)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 12))\n",
    "    fig.suptitle(\n",
    "        f\"ML4CE 2025/26 Data-driven Optimisation Coursework Results\\nSubmission: {submission}\",\n",
    "        fontsize=14\n",
    "    )\n",
    "\n",
    "    ax1 = fig.add_subplot(5, 1, 1)\n",
    "    ax2 = fig.add_subplot(5, 1, 2)\n",
    "    ax3 = fig.add_subplot(5, 1, 3)\n",
    "    ax4 = fig.add_subplot(5, 1, 4)\n",
    "    ax5 = fig.add_subplot(5, 1, 5)\n",
    "\n",
    "    ax1.plot(np.arange(len(t_ms)), t_ms, marker=\"o\", linestyle=\"None\", markersize=3)\n",
    "    ax1.set_ylabel(\"Time [ms]\")\n",
    "    ax1.set_xlabel(\"Iterations\")\n",
    "\n",
    "    ax2.plot(np.arange(len(Y)), Y, linewidth=2)\n",
    "    ax2.set_ylabel(\"Titre Conc. [g/L]\")\n",
    "    ax2.set_xlabel(\"Iterations\")\n",
    "\n",
    "    ax3.plot(np.arange(len(cum_t)), cum_t, linewidth=2)\n",
    "    ax3.set_ylabel(\"Cumulative Time [ms]\")\n",
    "    ax3.set_xlabel(\"Iterations\")\n",
    "\n",
    "    ax4.plot(np.arange(len(cum_Y)), cum_Y, linewidth=2)\n",
    "    ax4.set_ylabel(\"[g/L] Cumulative Titre Conc. [g/L]\")\n",
    "    ax4.set_xlabel(\"Iterations\")\n",
    "\n",
    "    ax5.plot(cum_t, cum_Y, linewidth=3, color=\"red\")\n",
    "    ax5.set_ylabel(\"Cumulative Titre Conc. [g/L]\")\n",
    "    ax5.set_xlabel(\"Cumulative Time [ms]\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    fig.savefig(out_png, dpi=200)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999101d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- Runner ----------------\n",
    "def make_initial_points(n_init=6):\n",
    "    pts = []\n",
    "    for i in range(n_init):\n",
    "        T = 30.0 + 10.0 * random.random()\n",
    "        pH = 6.0 + 2.0 * random.random()\n",
    "        F1 = 50.0 * random.random()\n",
    "        F2 = 50.0 * random.random()\n",
    "        F3 = 50.0 * random.random()\n",
    "        c = CELLTYPES[i % 3]\n",
    "        pts.append([T, pH, F1, F2, F3, c])\n",
    "    return pts\n",
    "\n",
    "\n",
    "def main():\n",
    "    X_initial = make_initial_points(6)\n",
    "\n",
    "    bo = BO(X_initial=X_initial, iterations=15, batch=5, objective_func=objective_func)\n",
    "\n",
    "    best = float(np.max(bo.Y))\n",
    "    print(\"Best objective value found:\", best)\n",
    "    print(\"Total evaluations:\", len(bo.Y))\n",
    "\n",
    "    # best-so-far per round (init + 15 rounds)\n",
    "    best_curve = []\n",
    "    y = bo.Y\n",
    "    best_curve.append(float(np.max(y[:6])))\n",
    "    for r in range(15):\n",
    "        end = 6 + (r + 1) * 5\n",
    "        best_curve.append(float(np.max(y[:end])))\n",
    "    print(\"Best-so-far per round (init + 15 rounds):\")\n",
    "    print(best_curve)\n",
    "    print(\"Total runtime measured (ms):\", float(np.sum(bo.time)))\n",
    "\n",
    "    plot_results(bo)\n",
    "    return bo\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
